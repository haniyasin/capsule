* как дальше жить
  В общем ситуация такая, изначально capsule - это база для caravan и поэтому его как бы нельзя было
  рассматривать как фреймворк общего назначения. Ну то есть сравнивать его скажем c Qt или даже с nodejs
  не стоит. Скорее его можно сравнивать с web api в понимании мозиллы. То есть некоторая песочница с
  расширенным апи для доступа ко всяким вещам. Но если это песочница, то как насчёт http_responder, не
  многовато ли для песочницы? Многовато. Поэтому как ни крути, получается что мы движемся в сторону Qt, но
  развиваем только те направления, которые нам нужны в caravan. Но никаких непреодолимых препятствий сделать
  поддержку работы с файлами или скажем сокетами - нет. 
  Отсюда большой вопрос куда двигаться, пишу это здесь и чтобы в голове не держать и в случае, если capsule
  будет пользоваться кто-то ещё, чтобы прочли и выссказались.

** по deployer
   Сейчас deployer, тот что собирает ваше приложение используя capsule modules работает только под nodejs.
   То для для bootstrap вам необходим nodejs. Потенциально, и я думаю над этим, он сможет работать и под
   gjs и почти на любой платформе, где есть доступ к файловой системе. Поддержка работы deployer на разных
   платформах автоматически принесёт в capsule поддержку работы с файлами. 
   Но есть более интересный вопрос, а стоит ли как-то так изменить deployer, чтобы он работал даже там,
   где нет файлов, скажем в браузере? То есть имеет ли смысл? Изначально я думал так: нужно приспосабливаться
   к условиям, а не создавать свои. Например: публиковать в android play уже собранное приложение, вместо того
   чтобы человека заходил на вебсайт, оно загружалось и у него в браузере собиралось.  Сейчас я продолжаю
   думать также, ибо это самый прямой путь, но есть некоторые сомнения. С другой стороны, ничего не мешает
   отложить обдумывание этого на долго:)

** по модулям
   Это главный вопрос, как уже было сказано выше, сейчас capsule это свой мирок. Но расширить его вполне
   возможно. Нужно лишь определять API, скажем для доступа к файлам, и реализовать его в виде модулей для
   разных платформ. Всё для этого сделанож. Вопрос по API к файлам уже почти решён, ибо от него зависит
   deployer, а deployer я убеждён должен работать максимально native, то есть даже там, где нет nodejs,
   но есть какая-то возможность исполнять полноценные javascript приложения. А коли API к файлам будет,
   также планируюется sound API, то что, socket API чем-то отличается? И да и нет. 
   Изначально, capsule должен был иметь достаточно высокоуровневые API, и так оно сейчас и есть. Скажем
   вместо прямого использования http_requester предпочитается использовать transport. Также и storage.
   По этой причине всякие file, socket API и прочие _не должны_ использоваться приложениями слишком часто,
   напрямую и тд. То есть выходит, что всё API будет делится на highlevel и lowlevel. Но тем не менее,
   причина почему в capsule highlevel API в почёте всё ещё здесь - (javascript, он вам не С с точки зрения
   производительности и писать на нём используя низкоуровневые api мягко говоря не очень эффективно). Эта
   причина может быть устранена только используя подход, описанный в metaproto, но это будет когда? Через
   лет тысячу! Поэтому пока я считаю так - lovlevel api могут появляться и будут появляться, но не должны
   широко использоваться, это было бы ошибкой.
** capsule, capsule, new capsule
*** краткое описание
   В общем уже давно, и где-то в документации наверное есть следы, думал о том чтобы можно было создавать
   capsule не только с помощью внешних инструментов(теперь это deployer), но и изнутри. Теперь пришло время
   об этом написать и начать уже двигаться. Что это даёт?:
   - возможность порождать процессы или потоки
     Строго говоря скорее процессы, чем потоки, но об этом дальше. Почему не всякие fork, clone и прощие
     create_proccess? Потому что нам важно не только создать отдельную нить, начинающуюся с некоторой
     функции. Нам важно получить полноценную capsule, с которой ещё было бы возможно относительно легко
     взаимодействовать. Без этого грошь цена, без простоты создания и простоты взаимодействия подобные
     возможности не будут использоваться как и не используются подавляющим числом приложением. А вот если
     нужно что-то кроме простого создания потока, то здесь fork или clone как минимум недостаточны( нужно
     же ещё простое средство коммуникации сообщениями). Но ещё и вредны, ведь кучу контекстов надо
     пересоздавать заново(новый duktape, частично новые модули и тд)

   - песочницы, изоляция кода, конфигурация
     здесь в основном для того, чтобы выполнять некоторый код предназначенный для строго определённых целей
     и предоставлять ему соответствующие возможности. Это не обязательно именно изоляция, скорее конфигурация
     среды. Например ui код может иметь доступ до Compositer и одновременно с этим иметь б'ольший приоритет.
     
*** Как это работает? 
    Естественно, что по разному в зависимости от платформы. В этом вообще вся суть capsule. Но всё таки в 
    одинаково в некотором смысле. Поэтому парочка примеров я думаю опишет ситуацию:
    + nodejs
      через child process создаётся отдельный процесс. Тут возможен вариант с fork + реинициализация, 
      посмотрим, но скорее всего exec с образом capsule + необходимая инициализация.
      В любом случае получается полностью самостоятельный процесс, от которого отключаются все родительские
      дескрипторы. Взаимодействие идёт с помощью сообщений. 

    + gjs
      через spawn_async. Впринципе также как и nodejs, разница тут не большая.
     
    + browser
      через webworker. Почти как и выше, но с той разницей, что в браузере webworker не имеет доступа к DOM,
      но подобные ограничения то есть то нет у разных платформ. Где-то можно сделать множество Compositer,
      как gjs, win32, а где-то только один - web, android. И причины ограничений часто разные.
      В общем здесь создаётся webworker с самостоятельным образом capsule и идёт с ним взаимодействие.

    + win32
      через CreateProcess. Похоже на nodejs и gjs, но тут просто создаётся cbc процесс с образом капсулы.

    У выше описанных случаев много общего, но и может быть много разного. Например способ взаимодействия.
    Во всех случаях используется интерфейс transport. Но реализация его разная, впрочем это свойственна 
    capsule в целом - единые интерфейсы, но разные реализации. В win32, gjs, nodejs разные capsule могут
    общаться с помощью pipe, sockets. А вот в web это уже собственный способ отправки сообщений webworker.

    Тут важно понять, что подход в создании новых capsule это скорее способ разбить приложение на множество 
    независимых модулей-процессов, нежели такие вещи как cluster в nodejs или те же webworker в чистом виде.
    А используемые там идеи вряд ли можно рассматривать как полезные и простые. Значит ли это, что new capsule
    нельзя использовать как ускоритель числодробления? Скорее да, чем нет. По крайней мере пока мы работаем
    с javascript, а не с когда-нибудь придущим  metalang это верно. Числодробить надо снизу, на уровне С.

    Естественно, что может быть так, что новые процессы, потоки или подобное просто не поддерживаются
    конкретной целевой платформой. Что в этом случае? Весь код, который использует new capsule также остаётся
    работоспособным, следуюя принципам capsule api. Но он становится однопоточным, а посыл сообщений работает
    как transport.direct - то есть прямой вызов функций. Возможно это и небольшой перерасход, а может и нет,
    если этот посыл сообщений и вовсе делается через native реализацию.
*** API
    Простейший пример:
    //ui.js
    var timer = require('modules/timer');
    timer.create(function(){ ui.destroy()}, 10000, false);
    modules.parent_transport.on_msg(function(body){console.log(body)});
    //capsulated.js
    var ui = new capsule('ui', { modules : 'Compositer'));
    ui.send("hello");
    ui.destroy();
    
    Впринципе тут ничего такого неясного нет. Создаётся ещё одна капсула, которая стартует с модуля ui и
    которой доступен только Compositer. Естественно, ей доступен ещё базовый набор модулей, без которых
    вообще сложно что-то сделать, но и это настраиваемо.
    Доступные модули можно посмотреть в объекте modules.
    Затем посылается сообщение новосозданной капсуле, оно принимается и отпечатывается.
    Поскольку транспорты можно прикручивать к dsa.mq, то получается, что каждый модуль сможет взаимодействовать
    с множеством модулей, если вам это нужно, но это уже не дело capsule, это слой выше. Забегая немного
    вперёд скажу, что в JSone предполагаются специальные механизмы для упрощения работы с этими возможностями
    и интеграции их в сервисы, чтобы как можно меньше нужно было заниматься вознёй.

    В зависимости от платформы, созданные capsule как могут жить самостоятельно после смерти родителя( если
    это самостоятельные процессы), так и умирать вместе с ним(если это потоки или webworker). Но в рамках
    capsule API мы считаем, что самостоятельно они не умирают и в коде _обязательно_ должны быть механизмы
    самозавершения. В нашем случае это простейшее самозавершение по таймеру, но обычно, в работающем коде,
    это должно быть завершение, если никакой работы нет и не предвидится(умер родитель, не передаётся 
    обязательный регулярный тик)
    
** container, обёртки, типы
*** описание и причины появления
    В capsule нам надо работать с разными объектами(binary buffer, image, video), словом разными
    объектами разного уровня.
    Но в javascript подобное не поддерживается по двум причинам:
    - низкоуровнево, нет поддержки в языке(привет binary buffer и отсутствие даже маломальского инструментария
    для работы с бинарными данными)
    - просто нафиг не надо и реализуется обычно на уровне API той или иной среды(например image это объект
      DOM в браузере, и чтобы его скажем создать прямо из кода, надо удалить гланды через жо, то есть
      создать blob, создать url по этому блобу и уже потом по этому url сделать image)
    
    А что надо нам? Простые механизмы работы с типами, которые используются в основных модулях capsule.
    Архитектура, которая позволит по мере надобности эти типы пополнять.
    Что значит простые? Всё просто, чтобы можно было создавать, добавлять, изменять и удалять просто, без
    всяких неочевидных телодвижений;
    
*** Как это работает
    Сильно по разному, в зависимости от платформы. Дам несколько примеров, чтобы было понятно:
    - browser 
      допустим нам нужен image, допустим для Compositer. Его ещё нужно будет откуда-то взять, допустим
      из хранилища.
      Упрощённо это будет выглядеть так:
      var image = io.image_read_file(id);
      comp.image_create({ height : '100%', width : '100%', source : image });
      А работать это будет так:
      В зависимости от того поддерживает ли наш браузер blob, в хранилище image хранится как blob или как base64
      Извлекаясь из хранилища image оборачивается в объект с разными удобными методами.
      Далее Compositer, при создании image, просто дёргает image.get_url, для получения url, не думая
      о всяких блобах, а сам image уже обрабатывает всё как надо. То есть либо создаёт строку urldata, либо
      создаёт url по блобу и возвращает.
      Здесь важно, get_url это один из методов, который поддерживается данной платформой capsule, её модулями,
      а для использования же приложениями предназначеные другие методы. То есть одни свойства есть всегда -
      те что для приложений, а другие зависят от платформы и предназначены для взаимодействия модулей.
      
    - cbc.win32
      рассмотрим тот же пример выше, только дам комментарий как это работает в cbc.win32
      Из файла вытаскивается содержимое, допустим это svg. Оно передаётся image модулю, который используя
      какую-либо libsvg создаёт объект и добавляет его к новосозданному image объекту.
      Затем этот image используется compositer в image_create, точнее он вызывает необходимые ему методы
      объекта для получения поверхности, которую затем и рисует.

    - nodejs
      Немного другой пример, с простым объектом, раньше это называли record, вот и мы его так назовём:
      var card = io.record_read_file(id);
      console.log(card.version); //выведет 1, так как card до этого только создавалась
      card.set_name('Vasya');
      console.log(card.version); //выведет 2, так как card имеет изменения, а старое значение name также сохранено
      transport.send(card);//сериализует, пересылает, причём включает все версии

      Теперь по порядку. Сначала читаем запись, допустим это карточка пользователя.
      Затем изменяем имя, что приводит к следующей версии карточки, подобно тому как работет vcs.
      После чего карточку отправляем по транспорту. Важно тут то, что явной сериализации не делается, но
      реально она происходит. Её производит сам объект record.
      В принципе ничего особо подкапотного тут не происходит, так как nodejs капсула полностью реализуется на
      javascript.
      Просто есть объект record, который имеет встроенный механизм версионирования и способен содержать
      произвольные поля. Этот объект можно создать как явно - new record, так и неявно - внутри read_record.
      Как происходит сериализация? Внутри transport.send вызывается card.serialize и на принимающей стороне
      deserialize. При этом, в зависимости от возможностей транспорта, card.serialize может быть указано
      сериализовать в json(если транспорт вроде http, только текст может гнать) или в bson(если транспорт
      бинарный типа сокетов, пайп или чего-либо ещё)
      
    Несколько объяснений в общем, что такое контейнер, тип вприципе и какими свойствами он обладает:
    - набор методов, стандартен для некоторого типа(например у типа video есть length). Этот набор формирует
      API

    - это обёртка над некоторыми данными, абстракция для удобной работы, делающая массу вещей неявно. 
      Например сериализацию, генерацию url в некоторых capsule и тд. Вы этого явно не делаете, отчего и удобства,
      но обёртка делает эту работу за вас. Главное, что гарантирует обёртка это единый вид объекта на всех
      поддерживаемых capsule платформах. То есть как бы был устроен скажем image внутри, снаружи он будет
      использоваться кодом приложения одинаково на всех платформах как одинаков и Compositer и другие модули.

    - это обёртка, которая скрывает низкоуровневость(тот же binary) или возможно сложность(то же video) данных.
      Без сокрытия из javascript либо вообще невозможно работать(например с бинарными данными) либо 
      чрезвычайно сложно(допустим вручную следить за тем как хранить изображение: urldata, blob, буфер итд)

    - это модули контейнеров, типов, которые определяют сами типы и как следствие - протокол работы с ними.
      То есть в простейшем случае: var image = new require('modules/types/image')(data); Вы не только
      получаете объект изображения, но и можете посмотреть какие он предоставляет механизмы работы с ним,
      методы, которые есть и для вашего программного кода и для модулей, которые его используют. То есть
      каждый объект включает в себя API для капсулированного кода и для кода модулей.

    - версионность. Важная, неотъемлемая часть всех контейнеров. Фактически, никакое деструктивное изменение
      контейнеров невозможно. А поскольку на контейнерах и будет строится вся работа с данными, то не возможно
      никак капсулированному коду работать с данными деструктивно. 
*** API
    У типа контейнера есть:
    - свой модуль в директории modules/types
    - конструктор, который подгружается require('modules/types/sometype');
      
    У каждого созданного c помощью new sometype() контейнера есть:
    - application API
      набор методов и свойств, начинающихся с букв, предназначенных для использования капсулированным кодом.
    - internal API
      набор методов и свойств, начинающихся с '_', предназначенных для использования модулями капсулы.
      Возможно также и наличие ещё более низкоуровневого API, допустим если сам тип и модули его исопльзующие
      сделаны из нативного теста(написаны не на javascript)
    - свойтво version, просто номер, отображающий версию. Каждый раз, когда контейнер изменяется версия 
      увеличивается.

    Пример работы:
    var itype = new require('modules/types/image');
    var btype = new require('modules/types/binary');
    var image = new image(base64_svg_data);
    console.log(image.height, image.width, image.size, image.depth);
    var binary = io.binary_bind_file('data.blob'); 
    //файл большой, аж гигабайт, но есть там текстовый фрагмент и где-то изображение затерялось
    var another_image = io.image_read_buffer(binary, 5000, 2000); //5000 - offset, 2000 length
    var text = io.text_read_buffer(binary, 200, 50); // 200 - offset, 50 length
    Думаю в целом логика понятна, хотя тут не обсуждалась io, которая является заменой недавно частично
    реализованной fs и всяких сокетов,но об этом позже.
    Также всё тут делается синхронно, но это лишь для простоты объяснения.

** IO
*** Описание, причины появления.
    Классическое название подсистемы input-output. Обычно так называют всё, что касается файлов, сокетов,
    портов, пайп, а иногда и разделямой памяти и прочих штуковин.
    В данном случае подразумевается то же самое.
    Зачем понадобилась ещё одна не придуманная тут вещь, почему не взять там уже готовые net, fs из nodejs,
    тем более, что реализация fs уже начата, поверх неё сейчас работает deployer.
    Причин несколько:
    1) сформировать простой API для работы ввода-вывода.
    2) API должен быть и синхронным и асинхронным. Это уже сделано в nodejs, но это просто требование.
    3) Он должен быть переносимым на разные платформы. В отличие от API nodejs и подобного, этот API
       должен работать и во всяких там браузерах.
    4) Интеграция с возможностями типов(контейнеров). Например вещи вроде сериализации делаются неявно,
       автоматически. Всё во имя упрощения кода, безошибочности. Тут просто надо сказать иная идеология.
       Большие и простые операции, вместо побайтных чтений потоков. Тут и потоков то нет.
    5) Простой, краткий async API для работы с потоками и буферами. Строго говоря как раз никаких потоков
       то и нет здесь, как и буферов. Только простая пакетная асинхронная работа с данными. Реально же
       потоки это просто абстракция. И не особо удачная с точки зрения простоты использования. Не спорю
       хорошо потоки вяжутся в С коде, но тянуть побайтовую работу, конкатенации и ручной или полуручной
       poll, select и прочие в javascript - это как минимум расточительно, а вообще просто глупо.

    Это чисто io API, а не всякие вещи вроде mkdir. Только соединение, чтение, запись, рассоединение. Для
    всего что можно соединять, читать, писать, рассоединять.
    Ещё важное замечание, не стоит думать, что этот API предназначен для замены всяких fs, net и прочих.
    Это API служит целям capsule и только им. А значит если какие-то возможности нельзя сделать, потому что
    нельзя из-за кросплатформенности, то их не будет. А это значит, что покрыть все возможности fs и
    net можно будет только с помощью не на всех платформах присутствующих фунциях. Сделать так можно и даже
    может так и будет. Но подобные то есть, то нет функции _никогда_ не будут использоваться капсулированными
    приложениями. То есть как и fs, будут отнесены к низкоуровневым возможностям.
    
*** Как это работает
    var io = require('modules/io');
    И поехали.
    С точки зрения реализации очень по разному. На одних платформах это просто набор javascript обёрток над
    встроенными механизмами io(nodejs, gjs, browser) + интеграция с типами. На других это чисто С реализация
    модуля с большой низкоуровневой реализацией и также же низкоуровневой интеграцией с типами, которая также
    сделан на С(cbc).
    В принципе любой, кто читал файлы и работал с сокетами не найдёт здесь откровений и объяснять ничего
    толком не нужно в общем, только в частностях API.
    Важно уяснить только одну вещь - вся работа идёт с типами, а не байтиками. Любые дополнительные работы
    с байтиками должны делаться через создание новых типов в капсуле и интеграцию их в io. Зачем так? Да
    потому что иначе работать подобное не будет, capsule это вам не nodejs и не jvm, переносимость на 
    уровне одной кодовой базы не обеспечить и даже цели такой нет.

  
*** API
    Для каждого типа есть собственные функции. Для одних типов функций больше, для других меньше.
**** Для большинства типов есть общие функции:
     create(path, type, async); //async - if true -asynchronic
     var object = open(path, type); //путь может содержать обозначение протокола и быть не только fs путём
     // но и сокетом и удалённой фс и ещё бог знает чем, главное чтобы io поддерживало это
     object.close();
     //если синхронный
     object.get_info();
     data_object = object.read();
     data_object = object.write();
     //или если асинхронный
     //cb(err, data_object)
     object.get_info(cb); 
     object.read(cb):
     object.write(cb);
**** Функции container
     Контейнер это буфер по сути, с ним можно работать произвольно, изменять, удалять там и тд. Но только
     объектами.

     new con();
     //если синхронный
     data_object = con.read(number); //прочитать объект под номером
     con.append(data_object); //добавить объект
     con.change(number, object);//изменить объект
     //если асинхронный - добавляется cb последним аргументом
**** Функции box
     box это абстракция чтения-записи в сокеты, пайпы и разделямую памятью(но только если предполагается лишь
     через неё пихать объекты, если накапливать, то надо использовать container). В общем всюду, куда
     можно пихать данные и потом вынимать(или реагировать на пихание) применим этот API
     К числу основных методов записи и чтения, добавлено следующее:

     box.on_arrive(cb);

**** binary
     Основная идея схожа с концепцией pack,unpack из perl и языками вроде idl, protobuf и последующей 
     сериализацией и десериализацией.
     То есть с одной стороны это методы вроде pack и unpack для упаковки данных в двоичную последовательность
     и наоборот. А с другой - это механизм описания структур данных для возможности данные сериализовать
     из объектов и десериализовать в объекты из двоичного буффера.    

     Допустим у нас есть такая C структура(подобное сплошь рядом в бинарных протоколах и форматах файлов)
     struct {
         short int checksumm;
	 int body_size;
	 int body_type;
	 char body_name[1];
     }
     И нам надо извлечь её, причём работать с ней удобно. Мы конечно же могли бы выдирать значение за
     значением и работать, как это делается в Buffer в nodejs или подобных убогих API. Но разве это удобно?
     Поэтому мы опишем нашу структуру:
     var header_type = {
         checksumm : 'int16';
	 body_size : 'int32';
	 body_type : 'int32';
	 body_name : 'Cstring';
     }
     и прочитаем её:
     var header = _binary.get_next(header_type);
     console.log('checksumm is: ' + header.checksumm, 'name is: ' + header.body_name);
     Теперь можно работать с объектом спокойно, как с обычным.
     где get_next - это возможность последовательно читать буффер, структура за структурой, передвигая позицию
     Далее мы можем и записать объект также просто:
     var header = {
         checksumm : 32,
	 body_size : 200,
	 body_type : 'string',
	 body_name : 'Message'
     }
     _binary.append(header_type, header);
     
     В случае, если не удаётся записать или прочитать структуру(например при записи выясняется что данные
     объекта не совпадают с его определением или при чтении выясняется что читаемые данные не совпадают
     с определением), выдаётся ошибка.
     
     new binary();
     new binary(type_definition, object); //создать бинарный массив из объекта по описанию
     binary.from_binary(type_definition, array); //создать объект из массива по описанию
     binary.get(offset, type_definition); //получить структуру по смещению
     binary.get_next(type_definition); // получить следующую структуру
     binary.set(offset, type_definition, object); //переписать структуру по смещению
     binary.append(type_definition, object) // добавить структуру

     Когда идёт работа с box(всякими сокетами и тд), то в основном просто создаются binary объекты, чтобы
     отправить их и используется from_binary. Хотя потенциально остаётся возможность использовать чисто
     binary поверх box без прямого использования box, скажем используя уставку каллбека вроде:
     binary.on_get_next(type_defition, callback);
     Но это надо обдумать. Вроде и просто и логично, но и ещё один слой.
**** примеры
//image example
var oio = io_open("file://", id, image, false);

// implicitly content loading
var _image = oio.bind(); //automatic reading later when calling get_data

//explicitly content loading
_image  = oio.read();

var cimage = comp.image_create({width : "100%", height : "100%"}, _image); //calling image.get_data()
transport.send('firstimage', _image);


//video example
//подобно тому как вверху, в общем также, так что не стоит тоже самое писать
//implicitly
transport.on_msg('movie', 
		 function(video){
		    comp.video_create({width : "100%", height: "100%"}, video);
		 });
transport.on_msg('movie',
		function(video){
		    var oio = io_create("file://" + id, true);
//		    oio.bind(video);
		    oio.write(video, function(err){ if(!err) console.log('усё хорошо');});
		});
//explicitly
transport.on_msg('movie',
		function(video){
		    video.preload({ length : -1}, function(){
				      var oio = io_create("file://" + id, true);
				      //		    oio.bind(video);
				      timer.create(function(){
						       oio.write(video, function(err){ if(!err) console.log('усё хорошо');});
						   }, 10000, false);
				  });
				  });
		
** capsule deployer, assembler
   <2015-02-17 Вт>
*** описание и причины появления
    Ну вот пожалуй случилось то, что я предполагал, но где-то внутри не особо хотел чтобы случалось: появилась
    необходимость собирать рабочий образ капсулированного приложения из другого приложения. Как так и зачем?
    Пример прост: вот у нас есть приложение, которое имеет простой список элементов. И мы хотим его передать
    кому-нибудь, этот список. Как мы можем это сделать? Конечно, мы можем сериализовать сам список и это
    мы сделаем, более того, мы сделаем это в любом случае. Но разве принимающая сторона обязательно имеет
    у себя это наше приложение? Не обязательно. Это как с pdf, его любят за то, что он везде одинаков и 
    легко читается(софта дефолтного полно). Вот и нам также. А значит нам надо принимающей стороне передать
    не только сериализованный список, но и наше капсулированное приложение. А как это сделать? Собрать его
    для принимающей стороны, добавить туда сериализованный список и принимающая сторона увидит точно то же,
    что видим мы. А поскольку принимающая сторона может иметь другую платформу, чем наша, то нам нужна не 
    просто возможность самодампа, но и возможность сборки. Вот такие дела, вот так вот двинул нас сюда
    caravan
*** API
    
**** example
     //собираем капсулированных самих себя
     var assembled = capsule.assemble(capsule.platforms.current, 'current');
     //добавляем наш список, он уже подготовленная коллекция
     assembled.module_add('playlist', playlist);
     //получаем наше капсулированное приложение в виде файлов и далее делаем что хотим
     var files = assembled.get_as_files();
